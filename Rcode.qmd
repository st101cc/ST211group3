---
title: "ST211mini project"
author: "Group4"
output: html
self-contained: true
editor:
    render-on-save: true
    preview: true
---

## Set up

```{r message=FALSE, warning=FALSE}
# set up
library(dplyr)       
library(tidyr)      
library(readr)      
library(lubridate)
library(arm)
library(tidyselect)
library(ggplot2)
library(car)
library(gridExtra)
```

```{r}
# Data Loading
data<-read.csv("data/RWNS_final.csv", header=TRUE,stringsAsFactors=TRUE)
```

# Have a look at the data

```{r}
head(data)
summary(data)
```

## `fiveac` & `fiveem` vs k4score

```{r warning=FALSE, message=FALSE}
fiveac_g<-ggplot(data=data, aes(x=fiveac,y=ks4score)) +
  geom_boxplot() +
  labs(title="Boxplot without Math & English",
         x="5 A*-C Subjects",
         y="Ks4score")

fiveem_g<-ggplot(data=data, aes(x=fiveem,y=ks4score)) +
  geom_boxplot() +
  labs(title="Boxplot with Math & English",
         x="5 A*-C Subjects (inc. Math&Eng)",
         y="Ks4score")

grid.arrange(fiveac_g, fiveem_g, nrow=1)
```

It's obvious that both median and IQR is higher for students who have 5 or more A\*-C subjects. This is quite intuitive as students who have more GCSE subjects that are grade from A star to C tend to have higher GCSE scores. However, the two plots with similar patterns inside seem to have no significant difference with each other. For the ease of model building, we decide to only include one variable -`fiveac`.

## `IDACI_n` vs k4score

By viewing the dataset, we can see that there are one columns that contain numerical variables which is **"IDACI_n"**. Here, we chose to first use `scatter plots` to see the relationship of this variable with the target variable. This is because with numerical data, the scatter plot can show `a best fitting line` which indicates the trending of the data.

```{r warning=FALSE, message=FALSE}
IDACI_g<-ggplot(data, aes(x = IDACI_n, y = ks4score)) + 
  geom_point(alpha=0.2, size=3, color="lightblue", stroke=1) + 
  geom_smooth(method = "lm",  
              se = FALSE) + 
  theme_minimal() + 
  labs(title = "Scatter Plot of Deprivation vs GCSE Scores with Fitted Line",
       x = "Index of Deprivation",
       y = "GCSE Scores")

IDACI_g
```

From the plot, we can see that there is a slightly downward trend in the fitted line, which indicates that the higher the deprivation index, the lower the GCSE scores. It's quite intuitive that students with more deprived background tend to receive less-qualified education, and thus resulting to lower GCSE scores.

However, it's not reasonable to conclude that the deprivation index is a significant factor that affects the GCSE scores from the plot. We need to further investigate the relationship between the deprivation index and the GCSE scores by using a **simple linear regression model**.

```{r}
# Simple linear regression model
IDACI_lm <- lm(ks4score ~ IDACI_n, data = data)
summary(IDACI_lm)
```

From the summary of the simple linear regression model, we can see that the negative relationship is statistically significant at 5% level. Therefore, we can conclude that the deprivation index is a significant factor that affects the GCSE scores, but it's not the only factor.

## Multicollinearity Check

There are some columns that we think may have correlations in between: `house`, `fsm`, `computer`, `tuition` and `IDACI_n`. In our common sense, we believe that students with high deprivation index are more likely to have rented houses, free school meals, no computers and low tuition fees. To do so, we began with testing the Variance Inflation Factors between these variables.

```{r}
ks4score.lm.1<-lm(ks4score~IDACI_n+fsm+house+computer+tuition,
               data=data)
car::vif(ks4score.lm.1)
```

Unsurprisingly, `computer` and `tuition` are highly correlated with each other with high VIF values of over 10. Therefore, we decide to keep `tuition` only and exclude `computer` variable.

```{r}
# Simple linear regression model for tuition
tuition_lm <- lm(ks4score ~ tuition, data = data)
summary(tuition_lm)
```
However, when running the regression model for tution and ks4score, we can see that tution only explains less than one percent of the variation in GCSE score. Hence, we will exclude this variable from our modeling. 

## `house` vs k4score

```{r warning=FALSE, message=FALSE}
house_g<-ggplot(data=data, aes(x=house,y=ks4score)) +
  geom_boxplot() +
  labs(title="Boxplot of Housing Status vs GCSE Scores",
         x="Housing Status",
         y="GCSE Scores")
house_g
```

From the boxplot, we can see that students with owned houses tend to have a higher GCSE score. What's more, the median of the column `other/DK/Ref` is lower than `owned` but higher than `rented`, showing a significance to the target variable. Therefore, we will keep the missing value for `house`.

## `fsm` vs k4score

```{r warning=FALSE, message=FALSE}
fsm_g<-ggplot(data=data, aes(x=fsm,y=ks4score)) +
  geom_boxplot() +
  labs(title="Boxplot of Free School Meal vs GCSE Scores",
         x="Free School Meal",
         y="GCSE Scores")
fsm_g
```

It has a relationship with GCSE scores.

### `sen` vs k4score
```{r}
ks4score.lm.2<-lm(ks4score~fsm+sen,
               data=data)
coef(ks4score.lm.2)
```
The coefficients output shows `NA` for `senYes`, which indicates that there is perfect multicollinearity or that the variable is a linear combination of other variables in the regression. Therefore, we decide to exclude `sen` from our model.

## `tuition` vs ks4score

```{r warning=FALSE, message=FALSE}
tuition_g<-ggplot(data=data, aes(x=tuition,y=ks4score)) +
  geom_boxplot() +
  labs(title="Boxplot of Tuition vs GCSE Scores",
         x="Tuition Paid or not",
         y="GCSE Scores")
tuition_g
```

`tuition` value also has a contribution to the change in GSCE score. It means that if parents pay for private classes in a subject also taught at school in the last 12 months, the student will have a better grade.

## `homework` vs k4score

```{r warning=FALSE, message=FALSE}
homework_g<-ggplot(data=data, aes(x=homework,y=ks4score)) +
  geom_boxplot() +
  labs(title="Boxplot of Homework vs GCSE Scores",
         x="Homework",
         y="GCSE Scores")
homework_g
```
It seems that students who do homework more often tend to have higher GCSE scores.

## `gender` vs k4score

```{r}
## gender: no clear relationship between gender and ks4score
ggplot(data, aes(x=gender,y=ks4score, color=gender)) + geom_boxplot() + labs(title = 'Boxplot between Gender and Ks4score')
```
From the boxplot, we can see that there is no clear relationship beteween gender and ks4score, so we will remove the gender variable from our predicition model. 

## `singlepar` vs k4score

```{r}
ggplot(data, aes(x=singlepar,y=ks4score, color=singlepar)) + geom_boxplot() + labs(title = 'Boxplot between Students with or without Single Parent and Ks4score')
```
Students without single parent have a higher overall ks4score than students with single parent.

```{r}
# Simple linear regression model for singlepar
singlepar_lm <- lm(ks4score ~ singlepar, data = data)
summary(singlepar_lm)
```
Although the p-value shows that the negative relationship between having a single parent and GCSE score is statistically significant, the R-squared value of 2.8% shows that singlepar explains a small variation in GCSE score, so we will exclude it from our modelling. 

## `attitude` vs k4score

```{r}
ggplot(data, aes(x=reorder(attitude, ks4score, median),y=ks4score, color=attitude)) + geom_boxplot() + labs(title = 'Boxplot between Attitude and Ks4score')
```
Students with very_high attitude tend to have higher median ks4score compared to students with very_low attitude.

```{r}
# Simple linear regression model for attitude
attitude_lm <- lm(ks4score ~ attitude, data = data)
summary(attitude_lm)
```
The regression model for attitude suggests that 5% of the variability in GCSE score can be explained by students' attitude. Although the attitude factor is statistically significantly, there are many other variables that are not accounted for that influence academic performance. 

## `FSMband` vs k4score

```{r}
ggplot(data, aes(x=FSMband,y=ks4score, color=FSMband)) + geom_boxplot()
```

Different percent of students in the school entitled to FSM have varying ks4score.

## `hiquam` vs k4score

```{r}
ggplot(data, aes(x=reorder(hiquamum, ks4score, median),y=ks4score, color=hiquamum)) + geom_boxplot() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```
Students with different level of mothers highest educational qualification have different ks4score, where degree_or_equivalent have the highest median ks4score and no_qualification has the lowest ks4score. 

## `k3` vs k4score

```{r}
# select subset of data for k3 variable
data_k3 <- data[c("ks4score","k3en", "k3ma", "k3sc")]
# tidy up the data for ggplot
tidydata_k3 <- data_k3 %>%
  pivot_longer(cols = -"ks4score", names_to="k3", values_to="level")
tidydata_k3
ggplot(tidydata_k3, aes(x=k3,y=ks4score, color=k3)) + geom_boxplot()
```
The boxplot of k3en, k3ma, and k3ec shows that there is no clear relationship between ks3 subject scores and ks4scores. Since the three variables are highly correlated with each other, they can be combined together when running the regression model. 

### `exclude` vs k4score
```{r}
ggplot(data, aes(x=exclude,y=ks4score, color=exclude)) + geom_boxplot() + labs(title = 'Boxplot between exclude and Ks4score')
```

Students with one ore more exclusions from school age 11-14 has a significantly lower ks4score compared to students without exclusions.

### `truancy` vs k4score
```{r}
ggplot(data, aes(x=truancy,y=ks4score, color=truancy)) + geom_boxplot() + labs(title = 'Boxplot between truancy and Ks4score')
```
Similar to exclusion, students who is traunt in the last 12 months has a lower ks4score compared to students without truancy. 

### `absent` vs k4score
```{r}
ggplot(data, aes(x=absent,y=ks4score, color=absent)) + geom_boxplot() + labs(title = 'Boxplot between absent and Ks4score')
```
Students who is absent for more than one month during Y9 has a lower ks4score than students who are not absent. 

Looking at the three boxplots above, we can see that students who are absent, truant, or excluded during school time generally performed worse on GCSE exams. Hence, the three predictors can be merged together when running regression models.

```{r}
# Simple linear regression model for absent, exclude, and truancy
absent_lm <- lm(ks4score ~ absent+exclude+truancy, data = data)
summary(absent_lm)
```
The linear model shows that all predictors other than absentYes and excludeNo are statistically significant. Together, these behavioral factors (absent, exclude, truancy) explain only 12% variability of the GCSE score. Since the truancyYes is the most statistically significant out of all three predictors, we will only keep truancy for our final data modeling. 

## `SECshort` vs k4score

```{r}
ggplot(data, aes(x=reorder(SECshort, ks4score, median),y=ks4score, color=SECshort)) + geom_boxplot() + labs(title = 'Boxplot between SECshort and Ks4score') + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

The boxplot for SECshort shows that the median ks4score for managerial is the highest, followed by intermediate, missing, and routine, semi-routine and unemployed.

## `parasp` and `pupasp` vs k4score

```{r}
ggplot(data, aes(x=parasp,y=ks4score, fill=pupasp)) + geom_boxplot() + labs(title = 'Boxplot between parasp, pupasp, and Ks4score')
```
The boxplot shows that students who want to continue in FTE after age 16 has a significantly higher ks4score in all three cases (no, yes, missing) for whether parent wishes YP to continue in FTE post 16.

```{r}
# Simple linear regression model for parasp and pupasp
pasp_lm <- lm(ks4score ~ parasp*pupasp, data = data)
summary(pasp_lm)
```
From the model above, we can see that pupaspYes shows a positive relationship with GCSE score, and the model explains around 12 percent of the variation in GCSE score. 
